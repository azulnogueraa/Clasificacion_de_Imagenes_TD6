{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "5DllB-4f8I9c",
        "k6cq9xMg-vkS",
        "s7oHMDAMMh40",
        "kPrFCUPCXhEt",
        "LnFjkiEui7Bb",
        "cI1seW25TVrg",
        "49_b_sJrorOH",
        "ab5XT2HShAUO",
        "9ixJB8iUlRna",
        "PggwqUVolaqA",
        "TgypBo92lfLy",
        "QxdzS5dibxW4",
        "Y35XiKfQcNcG",
        "LxuytoHQcpE_",
        "MhXmvriDcsud",
        "UvJSB_cadbVJ",
        "kZ8hHAv-dhvj",
        "fA4S2Jn_dvGS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c860e2a89e574a9781b0bda9569ba0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c0e93bcdecc4cfca753385a5221343a",
              "IPY_MODEL_883b0c2deb374ecf8df4c5c8837e7c87"
            ],
            "layout": "IPY_MODEL_cf25707fc6ec463c959b589b4fd44b4d"
          }
        },
        "2c0e93bcdecc4cfca753385a5221343a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44093b4fbb7b4af1927d25303a3c5ac4",
            "placeholder": "​",
            "style": "IPY_MODEL_8443ef359026455f8c28c9cd7fec5248",
            "value": "0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "883b0c2deb374ecf8df4c5c8837e7c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad49880112a442e6b66506b1b9c88e3e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ff631626bed449d9035a5665201f84a",
            "value": 1
          }
        },
        "cf25707fc6ec463c959b589b4fd44b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44093b4fbb7b4af1927d25303a3c5ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8443ef359026455f8c28c9cd7fec5248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad49880112a442e6b66506b1b9c88e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff631626bed449d9035a5665201f84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Configuración"
      ],
      "metadata": {
        "id": "5DllB-4f8I9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bds-Vlsm75G8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "36261666-693c-467b-df26-adc8647b4495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "# Configuración + Librerias\n",
        "\n",
        "!pip install -Uq wandb\n",
        "\n",
        "#librerias\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import v2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import wandb\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "#login de wandb\n",
        "wandb.login()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.manual_seed(7)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2"
      ],
      "metadata": {
        "id": "k6cq9xMg-vkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros"
      ],
      "metadata": {
        "id": "56vOqGUOo2Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "learning_rate = 0.02\n",
        "momentum =.9\n",
        "epochs = 10\n",
        "project_name = \"clasificación_img\""
      ],
      "metadata": {
        "id": "vkHTHvxDo10u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaciones"
      ],
      "metadata": {
        "id": "4RJuIWE9o6Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "targets_ = trainset.targets\n",
        "train_idx, val_idx = train_test_split(np.arange(len(targets_)), test_size=0.2, stratify=targets_)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler,batch_size=batch_size, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler,batch_size=batch_size, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "t7hoLkhU_R7y",
        "outputId": "e751bde9-53dc-49c5-db5a-0daab15d90c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13074900.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4b347fa73695>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mvalloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found or corrupted. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcalculate_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron simple"
      ],
      "metadata": {
        "id": "uU8FcpF3_t3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron simple\n",
        "\n",
        "class FC1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32*32*3, 32*32)\n",
        "        self.fc2 = nn.Linear(32*32, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3FC+ReLU\"\n",
        "# net = FC1()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "k5HITnSd-3a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aumentamos la cantidad de nodos al perceptron simple\n",
        "\n",
        "class FC2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32*32*3, 32*32*6)\n",
        "        self.fc2 = nn.Linear(32*32*6, 32*32)\n",
        "        self.fc3 = nn.Linear(32*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3FC_2+ReLU\"\n",
        "# net = FC2()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxQ6LVmeD4ZV",
        "outputId": "79798d64-71ac-436a-f77a-a39138a183d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FC2(\n",
              "  (fc1): Linear(in_features=3072, out_features=6144, bias=True)\n",
              "  (fc2): Linear(in_features=6144, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron Multicapa"
      ],
      "metadata": {
        "id": "Mw2kpiGjFZu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A la red que mejor performance dio le aumentamos una capa\n",
        "\n",
        "class FC3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32*32*3, 32*32*6)\n",
        "        self.fc21 = nn.Linear(32*32*6, 32*32*3)\n",
        "        self.fc22 = nn.Linear(32*32*3, 32*32)\n",
        "        self.fc3 = nn.Linear(32*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc21(x))\n",
        "        x = F.relu(self.fc22(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"4FC+ReLU\"\n",
        "# net = FC3()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GTJADt9Fcj5",
        "outputId": "379e64d4-f629-44b4-8db1-835d25957dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FC3(\n",
              "  (fc1): Linear(in_features=3072, out_features=6144, bias=True)\n",
              "  (fc21): Linear(in_features=6144, out_features=3072, bias=True)\n",
              "  (fc22): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# volvemos a aumentar una capa mas\n",
        "\n",
        "class FC4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32*32*3, 32*32*6)\n",
        "        self.fc21 = nn.Linear(32*32*6, 32*32*3)\n",
        "        self.fc22 = nn.Linear(32*32*3, 32*32*3)\n",
        "        self.fc23 = nn.Linear(32*32*3, 32*32)\n",
        "        self.fc3 = nn.Linear(32*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc21(x))\n",
        "        x = F.relu(self.fc22(x))\n",
        "        x = F.relu(self.fc23(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"5FC+ReLU\"\n",
        "# net = FC4()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOZ6SKd2IAuO",
        "outputId": "21bab147-01fd-437a-e649-8829370f9438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FC4(\n",
              "  (fc1): Linear(in_features=3072, out_features=6144, bias=True)\n",
              "  (fc21): Linear(in_features=6144, out_features=3072, bias=True)\n",
              "  (fc22): Linear(in_features=3072, out_features=3072, bias=True)\n",
              "  (fc23): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# volvemos a aumentar una capa mas\n",
        "\n",
        "class FC5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32*32*3, 32*32*6)\n",
        "        self.fc21 = nn.Linear(32*32*6, 32*32*3)\n",
        "        self.fc22 = nn.Linear(32*32*3, 32*32*3)\n",
        "        self.fc23 = nn.Linear(32*32*3, 32*32*3)\n",
        "        self.fc24 = nn.Linear(32*32*3, 32*32)\n",
        "        self.fc3 = nn.Linear(32*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc21(x))\n",
        "        x = F.relu(self.fc22(x))\n",
        "        x = F.relu(self.fc23(x))\n",
        "        x = F.relu(self.fc24(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"6FC+ReLU\"\n",
        "# net = FC5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w20BxMJWJ_DI",
        "outputId": "9de3fcce-c78c-4ad6-e72f-6f29dab70309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FC5(\n",
              "  (fc1): Linear(in_features=3072, out_features=6144, bias=True)\n",
              "  (fc21): Linear(in_features=6144, out_features=3072, bias=True)\n",
              "  (fc22): Linear(in_features=3072, out_features=3072, bias=True)\n",
              "  (fc23): Linear(in_features=3072, out_features=3072, bias=True)\n",
              "  (fc24): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss y optimización"
      ],
      "metadata": {
        "id": "fNi99QmgARi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "id": "zAL2MIihAc2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "iPo-addkAttQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project= project_name,\n",
        "    entity = 'tp3-td6',\n",
        "    name = experiment_name,\n",
        "\n",
        "    # Hiperparametros\n",
        "    config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"momentum\": momentum,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # Se obtinen los imputs (imagenes) y las labels\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # End of test section\n",
        "    # Val section\n",
        "    train_accuracy = 100 * train_correct / total\n",
        "    running_loss = running_loss/total\n",
        "\n",
        "    val_correct = 0\n",
        "    total =0\n",
        "    val_loss =0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    # End of test section\n",
        "\n",
        "    val_accuracy = 100 * val_correct / total\n",
        "    val_loss = val_loss / total\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_losses.append(running_loss / total)\n",
        "    val_losses.append(val_loss / total)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "\n",
        "    print(f\"Guardando el modelo para la época {best_epoch}.\")\n",
        "    torch.save(net.state_dict(), f'{experiment_name}.pth')\n",
        "\n",
        "    print('Epoch: {}/{}..'.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}..'.format(running_loss / total),\n",
        "          'Val loss: {:.3f}..'.format(val_loss/ total),\n",
        "          'Val accuracy: {:.3f}'.format(val_accuracy))\n",
        "\n",
        "    wandb.log({ \"train_accuracy\": train_accuracy,\n",
        "               \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": running_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"best_val_accuracy\": best_val_accuracy,\n",
        "                \"best_epoch\": best_epoch })\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "train_time = round(end - start)\n",
        "\n",
        "print(f'Training time: {str(train_time)} seconds.')\n",
        "\n",
        "wandb.log({'train_time': train_time})\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "BYO6VpXZAd-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3"
      ],
      "metadata": {
        "id": "s7oHMDAMMh40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros"
      ],
      "metadata": {
        "id": "VtBgQNHrqxDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parametros\n",
        "batch_size = 32\n",
        "learning_rate = 0.02\n",
        "momentum =.9\n",
        "epochs = 10\n",
        "project_name = \"clasificación_img\""
      ],
      "metadata": {
        "id": "mLJhtAnaMlE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75168918-6b7b-43ba-f9e6-8c5f0701048a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 44058320.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaciones"
      ],
      "metadata": {
        "id": "h2lqNwotqzwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "targets_ = trainset.targets\n",
        "train_idx, val_idx = train_test_split(np.arange(len(targets_)), test_size=0.2, stratify=targets_)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler,batch_size=batch_size, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler,batch_size=batch_size, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "z-gUudqgq0PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes Convolucionales"
      ],
      "metadata": {
        "id": "-vFzREroNuOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Red convolucional 1\n",
        "\n",
        "class CNN1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 32, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
        "                               out_channels = 64,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "                            # 64 canales de 8x8 pues a la salida de cada capa\n",
        "                            # convolucional se le aplica un maxpool de 2x2.\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"2Conv+2FC+ReLU\"\n",
        "# net = CNN1()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONFG8wC4NzFa",
        "outputId": "8ddca125-e303-4eb8-8fc7-23578eb8c3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN1(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Red convolucional 2 - se le agrega una capa convolucional adicional\n",
        "\n",
        "class CNN2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 32, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
        "                               out_channels = 64,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 64,\n",
        "                               out_channels = 64,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "\n",
        "                            # 64 canales de 8x8 pues a la salida de cada capa\n",
        "                            # convolucional se le aplica un maxpool de 2x2.\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3Conv+2FC+ReLU\"\n",
        "# net = CNN2()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_fx9a9WPQ_A",
        "outputId": "5db06a62-462e-4405-fe1e-68bcc6435a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN2(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Red convolucional 3 - se le agregan dos capas convolucionales adicionales\n",
        "\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 32, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
        "                               out_channels = 64,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 64,\n",
        "                               out_channels = 64,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels = 64,\n",
        "                               out_channels = 64,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "\n",
        "                            # 64 canales de 8x8 pues a la salida de cada capa\n",
        "                            # convolucional se le aplica un maxpool de 2x2.\n",
        "        self.fc1 = nn.Linear(64 * 2 * 2, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv4(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"4Conv+2FC+ReLU\"\n",
        "# net = CNN3()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6805PDvQn93",
        "outputId": "ae5394ba-b717-4452-e884-066a07074e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN3(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Red convolucional 2 - A el modelo con la cantidad de capas convolucionales que mejor performance dió, se le aumenta la cantidad de canales de salida\n",
        "\n",
        "class CNN4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.ReLU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3Conv+2FC_2+ReLU\"\n",
        "# net = CNN4()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfVU8KAYWCEQ",
        "outputId": "44434253-b38a-43b8-b81b-2f502d3563b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN5(\n",
              "  (conv1): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss y Optimizador"
      ],
      "metadata": {
        "id": "mGRlkfemMzSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "id": "XBely23tM8SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "oueK-wG9M81K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project= project_name,\n",
        "    entity = 'tp3-td6',\n",
        "    name = experiment_name,\n",
        "\n",
        "    # Hiperparametros\n",
        "    config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"momentum\": momentum,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # Se obtinen los imputs (imagenes) y las labels\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # End of test section\n",
        "    # Val section\n",
        "    train_accuracy = 100 * train_correct / total\n",
        "    running_loss = running_loss/total\n",
        "\n",
        "    val_correct = 0\n",
        "    total =0\n",
        "    val_loss =0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    # End of test section\n",
        "\n",
        "    val_accuracy = 100 * val_correct / total\n",
        "    val_loss = val_loss / total\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_losses.append(running_loss / total)\n",
        "    val_losses.append(val_loss / total)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "\n",
        "    print(f\"Guardando el modelo para la época {best_epoch}.\")\n",
        "    torch.save(net.state_dict(), f'{experiment_name}.pth')\n",
        "\n",
        "    print('Epoch: {}/{}..'.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}..'.format(running_loss / total),\n",
        "          'Val loss: {:.3f}..'.format(val_loss/ total),\n",
        "          'Val accuracy: {:.3f}'.format(val_accuracy))\n",
        "\n",
        "    wandb.log({ \"train_accuracy\": train_accuracy,\n",
        "               \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": running_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"best_val_accuracy\": best_val_accuracy,\n",
        "                \"best_epoch\": best_epoch })\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "train_time = round(end - start)\n",
        "\n",
        "print(f'Training time: {str(train_time)} seconds.')\n",
        "\n",
        "wandb.log({'train_time': train_time})\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "2gEE36KrNAAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 4"
      ],
      "metadata": {
        "id": "kPrFCUPCXhEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros"
      ],
      "metadata": {
        "id": "gPmwXxOXr800"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parametros\n",
        "batch_size = 32\n",
        "learning_rate = 0.02\n",
        "momentum =.9\n",
        "epochs = 10\n",
        "project_name = \"clasificación_img\""
      ],
      "metadata": {
        "id": "CEYIb59Sr8fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaciones"
      ],
      "metadata": {
        "id": "g3SdCmLEr_U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "targets_ = trainset.targets\n",
        "train_idx, val_idx = train_test_split(np.arange(len(targets_)), test_size=0.2, stratify=targets_)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler,batch_size=batch_size, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler,batch_size=batch_size, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "Y_RCSLbAXsPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LeakyReLU"
      ],
      "metadata": {
        "id": "mz4txM9VsHuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de activación - Probamos usar LeakyReLU como función de activación en todas las capas\n",
        "\n",
        "class CNN_LeakyReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.LeakyReLU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.LeakyReLU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.LeakyReLU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.LeakyReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3Conv+2FC_2+LeakyReLU\"\n",
        "# net = CNN_LeakyReLU()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "E8jJQDmpYDW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Swish"
      ],
      "metadata": {
        "id": "-QFo6KwesYuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de activación - Probamos usar SiLU como función de activación en todas las capas\n",
        "\n",
        "class CNN_SiLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.SiLU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.SiLU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.SiLU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.SiLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3Conv+2FC_2+SiLU\"\n",
        "# net = CNN_SiLU()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "1VWiuV3AZX_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GeLU"
      ],
      "metadata": {
        "id": "Yif95DsysqTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de activación - Probamos usar GELU como función de activación en todas las capas\n",
        "\n",
        "class CNN_GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# experiment_name = \"3Conv+2FC_2+GELU\"\n",
        "# net = CNN_GELU()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "o24MPgmca8Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss y Optimizador"
      ],
      "metadata": {
        "id": "moV4F8h_X2u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "id": "LHp0Ei3ZX7hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "qhqEzqOOX9m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project= project_name,\n",
        "    entity = 'tp3-td6',\n",
        "    name = experiment_name,\n",
        "\n",
        "    # Hiperparametros\n",
        "    config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"momentum\": momentum,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # Se obtinen los imputs (imagenes) y las labels\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # End of test section\n",
        "    # Val section\n",
        "    train_accuracy = 100 * train_correct / total\n",
        "    running_loss = running_loss/total\n",
        "\n",
        "    val_correct = 0\n",
        "    total =0\n",
        "    val_loss =0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    # End of test section\n",
        "\n",
        "    val_accuracy = 100 * val_correct / total\n",
        "    val_loss = val_loss / total\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_losses.append(running_loss / total)\n",
        "    val_losses.append(val_loss / total)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "\n",
        "    print(f\"Guardando el modelo para la época {best_epoch}.\")\n",
        "    torch.save(net.state_dict(), f'{experiment_name}.pth')\n",
        "\n",
        "    print('Epoch: {}/{}..'.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}..'.format(running_loss / total),\n",
        "          'Val loss: {:.3f}..'.format(val_loss/ total),\n",
        "          'Val accuracy: {:.3f}'.format(val_accuracy))\n",
        "\n",
        "    wandb.log({ \"train_accuracy\": train_accuracy,\n",
        "               \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": running_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"best_val_accuracy\": best_val_accuracy,\n",
        "                \"best_epoch\": best_epoch })\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "train_time = round(end - start)\n",
        "\n",
        "print(f'Training time: {str(train_time)} seconds.')\n",
        "\n",
        "wandb.log({'train_time': train_time})\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "A4KYmCdwX-aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 5"
      ],
      "metadata": {
        "id": "LnFjkiEui7Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros"
      ],
      "metadata": {
        "id": "k91xBn63s_96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parametros\n",
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "momentum =.9\n",
        "epochs = 10\n",
        "project_name = \"clasificación_img\""
      ],
      "metadata": {
        "id": "vPdgKpMb_grV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaciones"
      ],
      "metadata": {
        "id": "oM6n2McCtBiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "targets_ = trainset.targets\n",
        "train_idx, val_idx = train_test_split(np.arange(len(targets_)), test_size=0.2, stratify=targets_)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler,batch_size=batch_size, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler,batch_size=batch_size, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnqqAFXQjBxi",
        "outputId": "5299cb70-0966-40a6-b930-01c4bb076d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red"
      ],
      "metadata": {
        "id": "W6Ke3r4utFJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizamos el mejor modelo obtenido hasta el momento.\n",
        "\n",
        "class EJ5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Z2sCGICmjYrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss y Optimizador"
      ],
      "metadata": {
        "id": "xH20B4oWjC_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SGD"
      ],
      "metadata": {
        "id": "GonW4fvpP5-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.02\n",
        "# experiment_name = \"3CNN+2FC+GELU+SGD\"\n",
        "# net = EJ5()\n",
        "# net.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "id": "CeAQclKr_0GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adagrad"
      ],
      "metadata": {
        "id": "yPImgz7CmX_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.02\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adagrad\"\n",
        "# net = EJ5()\n",
        "# net.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adagrad(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "w9mXQw9WjIze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adam"
      ],
      "metadata": {
        "id": "-1HnXRndDXPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.001\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam\"\n",
        "# net = EJ5()\n",
        "# net.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "JpG7XD5qPmjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.0001\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2\"\n",
        "# net = EJ5()\n",
        "# net.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "-jcAfcWIDPTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "AvLyQRNejK6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project= project_name,\n",
        "    entity = 'tp3-td6',\n",
        "    name = experiment_name,\n",
        "\n",
        "    # Hiperparametros\n",
        "    config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"momentum\": momentum,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # Se obtinen los imputs (imagenes) y las labels\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # End of test section\n",
        "    # Val section\n",
        "    train_accuracy = 100 * train_correct / total\n",
        "    running_loss = running_loss/total\n",
        "\n",
        "    val_correct = 0\n",
        "    total =0\n",
        "    val_loss =0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    # End of test section\n",
        "\n",
        "    val_accuracy = 100 * val_correct / total\n",
        "    val_loss = val_loss / total\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_losses.append(running_loss / total)\n",
        "    val_losses.append(val_loss / total)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "\n",
        "    print(f\"Guardando el modelo para la época {best_epoch}.\")\n",
        "    torch.save(net.state_dict(), f'{experiment_name}.pth')\n",
        "\n",
        "    print('Epoch: {}/{}..'.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}..'.format(running_loss / total),\n",
        "          'Val loss: {:.3f}..'.format(val_loss/ total),\n",
        "          'Val accuracy: {:.3f}'.format(val_accuracy))\n",
        "\n",
        "    wandb.log({ \"train_accuracy\": train_accuracy,\n",
        "               \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": running_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"best_val_accuracy\": best_val_accuracy,\n",
        "                \"best_epoch\": best_epoch })\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "train_time = round(end - start)\n",
        "\n",
        "print(f'Training time: {str(train_time)} seconds.')\n",
        "\n",
        "wandb.log({'train_time': train_time})\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c860e2a89e574a9781b0bda9569ba0e7",
            "2c0e93bcdecc4cfca753385a5221343a",
            "883b0c2deb374ecf8df4c5c8837e7c87",
            "cf25707fc6ec463c959b589b4fd44b4d",
            "44093b4fbb7b4af1927d25303a3c5ac4",
            "8443ef359026455f8c28c9cd7fec5248",
            "ad49880112a442e6b66506b1b9c88e3e",
            "9ff631626bed449d9035a5665201f84a"
          ]
        },
        "id": "tBmSrcD5jM2m",
        "outputId": "a4e150d2-5384-4e21-bbea-6f0f662b1932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231104_165344-8mzf7wvo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img/runs/8mzf7wvo' target=\"_blank\">3CNN+2FC+GELU+Adam_2</a></strong> to <a href='https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img' target=\"_blank\">https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img/runs/8mzf7wvo' target=\"_blank\">https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img/runs/8mzf7wvo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 0.189\n",
            "[1,   400] loss: 0.343\n",
            "[1,   600] loss: 0.488\n",
            "[1,   800] loss: 0.624\n",
            "[1,  1000] loss: 0.753\n",
            "[1,  1200] loss: 0.875\n",
            "Guardando el modelo para la época 0.\n",
            "Epoch: 1/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 58.960\n",
            "[2,   200] loss: 0.115\n",
            "[2,   400] loss: 0.226\n",
            "[2,   600] loss: 0.335\n",
            "[2,   800] loss: 0.439\n",
            "[2,  1000] loss: 0.541\n",
            "[2,  1200] loss: 0.639\n",
            "Guardando el modelo para la época 1.\n",
            "Epoch: 2/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 65.560\n",
            "[3,   200] loss: 0.092\n",
            "[3,   400] loss: 0.183\n",
            "[3,   600] loss: 0.269\n",
            "[3,   800] loss: 0.357\n",
            "[3,  1000] loss: 0.441\n",
            "[3,  1200] loss: 0.527\n",
            "Guardando el modelo para la época 2.\n",
            "Epoch: 3/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 68.540\n",
            "[4,   200] loss: 0.077\n",
            "[4,   400] loss: 0.153\n",
            "[4,   600] loss: 0.229\n",
            "[4,   800] loss: 0.304\n",
            "[4,  1000] loss: 0.378\n",
            "[4,  1200] loss: 0.452\n",
            "Guardando el modelo para la época 3.\n",
            "Epoch: 4/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 72.040\n",
            "[5,   200] loss: 0.063\n",
            "[5,   400] loss: 0.126\n",
            "[5,   600] loss: 0.192\n",
            "[5,   800] loss: 0.256\n",
            "[5,  1000] loss: 0.322\n",
            "[5,  1200] loss: 0.389\n",
            "Guardando el modelo para la época 4.\n",
            "Epoch: 5/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 73.840\n",
            "[6,   200] loss: 0.054\n",
            "[6,   400] loss: 0.109\n",
            "[6,   600] loss: 0.165\n",
            "[6,   800] loss: 0.223\n",
            "[6,  1000] loss: 0.280\n",
            "[6,  1200] loss: 0.337\n",
            "Guardando el modelo para la época 5.\n",
            "Epoch: 6/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 74.070\n",
            "[7,   200] loss: 0.047\n",
            "[7,   400] loss: 0.095\n",
            "[7,   600] loss: 0.144\n",
            "[7,   800] loss: 0.195\n",
            "[7,  1000] loss: 0.243\n",
            "[7,  1200] loss: 0.291\n",
            "Guardando el modelo para la época 6.\n",
            "Epoch: 7/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 74.610\n",
            "[8,   200] loss: 0.038\n",
            "[8,   400] loss: 0.079\n",
            "[8,   600] loss: 0.120\n",
            "[8,   800] loss: 0.161\n",
            "[8,  1000] loss: 0.204\n",
            "[8,  1200] loss: 0.246\n",
            "Guardando el modelo para la época 7.\n",
            "Epoch: 8/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 75.540\n",
            "[9,   200] loss: 0.031\n",
            "[9,   400] loss: 0.066\n",
            "[9,   600] loss: 0.100\n",
            "[9,   800] loss: 0.135\n",
            "[9,  1000] loss: 0.170\n",
            "[9,  1200] loss: 0.206\n",
            "Guardando el modelo para la época 7.\n",
            "Epoch: 9/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 74.720\n",
            "[10,   200] loss: 0.026\n",
            "[10,   400] loss: 0.052\n",
            "[10,   600] loss: 0.080\n",
            "[10,   800] loss: 0.108\n",
            "[10,  1000] loss: 0.137\n",
            "[10,  1200] loss: 0.166\n",
            "Guardando el modelo para la época 7.\n",
            "Epoch: 10/10.. Training loss: 0.000.. Val loss: 0.000.. Val accuracy: 74.270\n",
            "Training time: 240 seconds.\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.091085…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c860e2a89e574a9781b0bda9569ba0e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>▁▂▃▄▅▆▇███</td></tr><tr><td>best_val_accuracy</td><td>▁▄▅▇▇▇████</td></tr><tr><td>train_accuracy</td><td>▁▃▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▇▇▇███▇</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_accuracy</td><td>75.54</td></tr><tr><td>train_accuracy</td><td>90.8925</td></tr><tr><td>train_loss</td><td>0.00869</td></tr><tr><td>train_time</td><td>240</td></tr><tr><td>val_accuracy</td><td>74.27</td></tr><tr><td>val_loss</td><td>0.02652</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">3CNN+2FC+GELU+Adam_2</strong> at: <a href='https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img/runs/8mzf7wvo' target=\"_blank\">https://wandb.ai/tp3-td6/clasificaci%C3%B3n_img/runs/8mzf7wvo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231104_165344-8mzf7wvo/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 6"
      ],
      "metadata": {
        "id": "cI1seW25TVrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros"
      ],
      "metadata": {
        "id": "YGPiiNX4upzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parametros\n",
        "batch_size = 16 #32 #64\n",
        "learning_rate = 0.0001\n",
        "momentum =.9\n",
        "epochs = 10 #30\n",
        "project_name = \"clasificación_img\""
      ],
      "metadata": {
        "id": "31QLrtuaTavt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaciones"
      ],
      "metadata": {
        "id": "yR-T3-HburSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "targets_ = trainset.targets\n",
        "train_idx, val_idx = train_test_split(np.arange(len(targets_)), test_size=0.2, stratify=targets_)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler,batch_size=batch_size, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler,batch_size=batch_size, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "9UI37takTdlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red"
      ],
      "metadata": {
        "id": "eYn6p2nkuuXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizamos el mejor modelo obtenido hasta el momento.\n",
        "\n",
        "class EJ5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "v4qN-OwsThS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentos"
      ],
      "metadata": {
        "id": "qmrgAb1XvSRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.0001, batch size 16 y Epocas 10\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+batch16+Epoch10\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "tmISuLUHNpCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.0001, batch size 64 y Epocas 10\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+batch64+Epoch10\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "lN44tPKuMMuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.0001, batch size 64 y Epocas 30\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+batch64+Epoch30\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "gyje_DtYT-s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss y Optimizador"
      ],
      "metadata": {
        "id": "CQ4zTQms1cae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "iM9sUHDX1c7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "OrYrzMP31NBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project= project_name,\n",
        "    entity = 'tp3-td6',\n",
        "    name = experiment_name,\n",
        "\n",
        "    # Hiperparametros\n",
        "    config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"momentum\": momentum,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # Se obtinen los imputs (imagenes) y las labels\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # End of test section\n",
        "    # Val section\n",
        "    train_accuracy = 100 * train_correct / total\n",
        "    running_loss = running_loss/total\n",
        "\n",
        "    val_correct = 0\n",
        "    total =0\n",
        "    val_loss =0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    # End of test section\n",
        "\n",
        "    val_accuracy = 100 * val_correct / total\n",
        "    val_loss = val_loss / total\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_losses.append(running_loss / total)\n",
        "    val_losses.append(val_loss / total)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "\n",
        "    print(f\"Guardando el modelo para la época {best_epoch}.\")\n",
        "    torch.save(net.state_dict(), f'{experiment_name}.pth')\n",
        "\n",
        "    print('Epoch: {}/{}..'.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}..'.format(running_loss / total),\n",
        "          'Val loss: {:.3f}..'.format(val_loss/ total),\n",
        "          'Val accuracy: {:.3f}'.format(val_accuracy))\n",
        "\n",
        "    wandb.log({ \"train_accuracy\": train_accuracy,\n",
        "               \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": running_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"best_val_accuracy\": best_val_accuracy,\n",
        "                \"best_epoch\": best_epoch })\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "train_time = round(end - start)\n",
        "\n",
        "print(f'Training time: {str(train_time)} seconds.')\n",
        "\n",
        "wandb.log({'train_time': train_time})\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "kiHsDxgeULUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "lL9-PlUcfMSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 7"
      ],
      "metadata": {
        "id": "49_b_sJrorOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros"
      ],
      "metadata": {
        "id": "rmxoRyy2wjig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "momentum =.9\n",
        "epochs = 30\n",
        "project_name = \"clasificación_img\""
      ],
      "metadata": {
        "id": "U-o91SnhpBAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaciones"
      ],
      "metadata": {
        "id": "_D6nn5iOwk8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomentar la transformación que se desea aplicar.\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(degrees = (0,20)),\n",
        "    # transforms.RandomCrop((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0, 1)\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    # Acá no aplicamos las otras transformaciones, porque ya no estamos en entrenamiento.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0, 1)\n",
        "])"
      ],
      "metadata": {
        "id": "PcftdtZLo7a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "\n",
        "targets_ = trainset.targets\n",
        "train_idx, val_idx = train_test_split(np.arange(len(targets_)), test_size=0.2, stratify=targets_)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler,batch_size=batch_size, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler,batch_size=batch_size, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vT53NV0pOd0",
        "outputId": "7849f07e-961a-440b-cb9c-a2ed7615368c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red convolucional original"
      ],
      "metadata": {
        "id": "ab5XT2HShAUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Probamos regularizando con nuestra red convolucional del punto anterior (con data augmentation y dropout)\n",
        "\n",
        "class EJ5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "s7a8lMX2plTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red con Dropout"
      ],
      "metadata": {
        "id": "Tz9sE_gAxN5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EJ5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,   # 1 canal de entrada.\n",
        "                               out_channels = 256, # 32 canales de salida.\n",
        "                               kernel_size = 3,   # Kernel 3x3.\n",
        "                               stride = 1,        # Pasos de 1.\n",
        "                               padding = 1)       # Padding de 1 para mantener el tamaño.\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels = 256,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512,\n",
        "                               out_channels = 128,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 1,\n",
        "                               padding = 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        # self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.conv1(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv2(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = nn.GELU()(self.conv3(x))\n",
        "        x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        # x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "9xOoOOTNxNUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red con Batch Norm"
      ],
      "metadata": {
        "id": "9ixJB8iUlRna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Agregamos la barch normalization ya que VGG la usa y podria mejorar nuesta performance (hay que ver si dejamos el dropout o no)\n",
        "\n",
        "class EJ5_batch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(256)  # Agrega una capa de BatchNorm2d después de la convolución\n",
        "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(512)  # Agrega una capa de BatchNorm2d después de la convolución\n",
        "        self.conv3 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)  # Agrega una capa de BatchNorm2d después de la convolución\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.bn1(self.conv1(x)))  # Aplica BatchNorm después de la convolución\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "        x = nn.GELU()(self.bn2(self.conv2(x)))  # Aplica BatchNorm después de la convolución\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "        x = nn.GELU()(self.bn3(self.conv3(x)))  # Aplica BatchNorm después de la convolución\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Y30kuBPMjXR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red con batch y dropout"
      ],
      "metadata": {
        "id": "PggwqUVolaqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EJ5_batch_dropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(512)\n",
        "        self.conv3 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.dropout = nn.Dropout(0.2)  # Capa de dropout con probabilidad 0.2\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GELU()(self.bn1(self.conv1(x)))\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "        x = nn.GELU()(self.bn2(self.conv2(x)))\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "        x = nn.GELU()(self.bn3(self.conv3(x)))\n",
        "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.GELU()(self.fc1(x))\n",
        "        x = self.dropout(x)  # Aplicar dropout a la salida de la primera capa lineal\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "e7PvOBNSlAbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentos"
      ],
      "metadata": {
        "id": "TgypBo92lfLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# agregamos horizontal flip con probabilidad default.\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+HFlip\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "hnFMIECrpoNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos dropout sin data augmentation\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+Dropout\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "_haoZWA2Qx2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos Random Rotation\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+Rotation\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "bliBM1JwotLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos Random Crop\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+Crop\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "3bj_CwcjtU8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agregamos rotacion de 0 a 20.\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+HFlip+Rotation\"\n",
        "# net = EJ5()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "PVr7Tml7uDQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentación extra"
      ],
      "metadata": {
        "id": "U1RTCMb5yZa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos con batch norm\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+BatchNorm\"\n",
        "# net = EJ5_batch()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "XwZGnCBAzraT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos con batch norm y dropout de 0.2\n",
        "# experiment_name = \"3CNN+2FC+GELU+Adam_2+BatchNorm+Dropout\"\n",
        "# net = EJ5_batch_dropout()\n",
        "# net.to(device)"
      ],
      "metadata": {
        "id": "RsNyCUyaPx9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss y Optimizador"
      ],
      "metadata": {
        "id": "QxdzS5dibxW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "7KXeWaiVuMz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "Y35XiKfQcNcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project= project_name,\n",
        "    entity = 'tp3-td6',\n",
        "    name = experiment_name,\n",
        "\n",
        "    # Hiperparametros\n",
        "    config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"momentum\": momentum,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # Se obtinen los imputs (imagenes) y las labels\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # End of test section\n",
        "    # Val section\n",
        "    train_accuracy = 100 * train_correct / total\n",
        "    running_loss = running_loss/total\n",
        "\n",
        "    val_correct = 0\n",
        "    total =0\n",
        "    val_loss =0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    # End of test section\n",
        "\n",
        "    val_accuracy = 100 * val_correct / total\n",
        "    val_loss = val_loss / total\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_losses.append(running_loss / total)\n",
        "    val_losses.append(val_loss / total)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_val_accuracy = val_accuracy\n",
        "\n",
        "\n",
        "    print(f\"Guardando el modelo para la época {best_epoch}.\")\n",
        "    torch.save(net.state_dict(), f'{experiment_name}.pth')\n",
        "\n",
        "    print('Epoch: {}/{}..'.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}..'.format(running_loss / total),\n",
        "          'Val loss: {:.3f}..'.format(val_loss/ total),\n",
        "          'Val accuracy: {:.3f}'.format(val_accuracy))\n",
        "\n",
        "    wandb.log({ \"train_accuracy\": train_accuracy,\n",
        "               \"val_accuracy\": val_accuracy,\n",
        "                \"train_loss\": running_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"best_val_accuracy\": best_val_accuracy,\n",
        "                \"best_epoch\": best_epoch })\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "train_time = round(end - start)\n",
        "\n",
        "print(f'Training time: {str(train_time)} seconds.')\n",
        "\n",
        "wandb.log({'train_time': train_time})\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "caqWVc99pznD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 8"
      ],
      "metadata": {
        "id": "xZ6fEvBQYrcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### El ejercicio 8 lo resolvimos en otro collab dado que ninguna de nuestras computadoras estaba pudiendo conectarse a la GPU del collab. La unica forma que se nos ocurrio para correr el testeo fue crear otro collab para usar esa GPU."
      ],
      "metadata": {
        "id": "cq3Z_Jj9YuaH"
      }
    }
  ]
}