{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> <font style=\"bold\"> TD VI: Inteligencia Artificial </font></h1>\n",
    "    <h2><font style=\"bold\">Trabajo práctico 3: Clasificación de imágenes </font></h2>\n",
    "    <h3><font style=\"bold\">Integrantes:</font></h3>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <h4><ul>\n",
    "        <li>Noguera Azul</li>\n",
    "        <li>Gonzalez Rocio</li>\n",
    "        <li>Guledjian Patricio</li>\n",
    "        </ul>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "<span style=color:lightblue> Crearse una cuenta en Weights and Biases y linkear la notebook a este. Cada experimento deberá contener nombres dicientes y almacenar los (hiper)parámetros de configuración del mismo. Deberá separar los sets de datos en entrenamiento, validación y test. Utilizando solamente los sets de entrenamiento y validación, registrar la loss en train y validación en cada iteración que considere conveniente. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este trabajo práctico es evaluar los distintos hiperparámetros encontrados durante el\n",
    "entrenamiento de una red neuronal, evaluarlos y elegir el conjunto de parámetros más óptimos.\n",
    "En el marco de este trabajo práctico, se realizará un clasificador de imágenes CIFAR-10.\n",
    "\n",
    "CIFAR-10 es un conjunto de datos que contiene 60,000 imágenes de 10 clases de pájaros, gatos, venados, perros, ranas, caballos, barcos y camiones; y se considera un conjunto de datos típico para problemas de visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos variando cantidad de capas densas, nodos, hidden layers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el proceso de experimentación con perceptrones, adoptamos un enfoque sistemático y justificado para evaluar diferentes arquitecturas y configuraciones. A continuación, se detalla la secuencia adoptada y las razones subyacentes de cada elección:\n",
    "\n",
    "**Modelo Base - Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3FC+ReLU: </span>\n",
    "Iniciamos nuestra serie de pruebas con un modelo de perceptrón simple, compuesto por una única capa y un conjunto restringido de 1024 unidades ocultas. Esta configuración se eligió con el propósito de establecer un estándar inicial, lo que nos permitiría discernir el umbral de rendimiento básico asociado a nuestro conjunto de datos. El desempeño alcanzado por este modelo fue de un 49.61% de precisión en su mejor época.\n",
    "\n",
    "**Incremento de Capacidad en Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3FC_2+ReLU: </span>\n",
    "Preservando una estructura de capa ocult única, decidimos expandir la capacidad del modelo aumentando significativamente el número de neuronas. El total de unidades ocultas en este modelo revisado ascendió a 6144. Esta modificación fue realizada con el objetivo de investigar el impacto que una mayor capacidad, sin añadir profundidad adicional, podría tener sobre el desempeño del modelo. El rendimiento alcanzado por esta configuración fue de un 50.23% de precisión en su mejor época.\n",
    "\n",
    "**Introducción al Perceptrón Multicapa:** \n",
    "\n",
    "Se implementaron modelos con cuatro capas en total, basándonos en resultados anteriores:\n",
    "\n",
    "<span style=text-decoration:underline> 4FC+ReLU: </span>\n",
    "En el primer modelo multicapa, la estructura se derivó de la configuración óptima observada en los experimentos anteriores de perceptrón simple, añadiendo una capa adicional. El total de unidades ocultas en este nuevo modelo ascendió a 9216. Esta adición tenía como objetivo discernir el impacto de una mayor profundidad en la capacidad de extracción de características del modelo. El rendimiento alcanzado por esta configuración fue de un 52.88% de precisión en su mejor época.\n",
    "\n",
    "**Ampliación del Perceptrón Multicapa:** \n",
    "\n",
    "<span style=text-decoration:underline> 5FC+ReLU: </span>\n",
    "Frente a la mejora observada al incrementar la capacidad de una capa oculta adicional en el modelo previo, se procedió a implementar un modelo con cinco capas, tomando como base la arquitectura que previamente demostró ser más eficiente. La motivación detrás de esta ampliación radicaba en investigar si la adición progresiva de profundidad continuaría aportando mejoras significativas al rendimiento o si eventualmente se llegaría a un punto de rendimiento estancado o de saturación. Esta versión del modelo logró un desempeño de 54.99% de precisión en su mejor época.\n",
    "\n",
    "En términos de resultados, a pesar de las variaciones arquitectónicas implementadas, no se observaron discrepancias significativas en el rendimiento entre modelos. Aunque el modelo con cinco capas demostró ser marginalmente superior, la accuracy global promedio permaneció en torno al 50%. \n",
    "\n",
    "Una interpretación posible es que la utilización de capas lineales podría estar limitando la capacidad de los modelos para discernir y aprender relaciones más complejas presentes en el conjunto de datos. Es por ello que en las proximas secciones se exploraran las capas convolucionales.\n",
    "\n",
    "A continuación se presentan los resultados obtenidos para los modelos en wandb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/best_val_accuracy_2.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/train_time_2.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_accuracy_2.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_accuracy_2.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_loss_2.png\" alt=\"Train Loss\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_loss_2.png\" alt=\"Validation Loss\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
