{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> <font style=\"bold\"> TD VI: Inteligencia Artificial </font></h1>\n",
    "    <h2><font style=\"bold\">Trabajo práctico 3: Clasificación de imágenes </font></h2>\n",
    "    <h3><font style=\"bold\">Integrantes:</font></h3>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <h4><ul>\n",
    "        <li>Noguera Azul</li>\n",
    "        <li>Gonzalez Rocio</li>\n",
    "        <li>Guledjian Patricio</li>\n",
    "        </ul>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "<span style=color:lightblue> Crearse una cuenta en Weights and Biases y linkear la notebook a este. Cada experimento deberá contener nombres dicientes y almacenar los (hiper)parámetros de configuración del mismo. Deberá separar los sets de datos en entrenamiento, validación y test. Utilizando solamente los sets de entrenamiento y validación, registrar la loss en train y validación en cada iteración que considere conveniente. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este trabajo práctico es evaluar los distintos hiperparámetros encontrados durante el\n",
    "entrenamiento de una red neuronal, evaluarlos y elegir el conjunto de parámetros más óptimos.\n",
    "En el marco de este trabajo práctico, se realizará un clasificador de imágenes CIFAR-10.\n",
    "\n",
    "CIFAR-10 es un conjunto de datos que contiene 60,000 imágenes de 10 clases de pájaros, gatos, venados, perros, ranas, caballos, barcos y camiones; y se considera un conjunto de datos típico para problemas de visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos variando cantidad de capas densas, nodos, hidden layers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el proceso de experimentación con perceptrones, adoptamos un enfoque sistemático y justificado para evaluar diferentes arquitecturas y configuraciones. A continuación, se detalla la secuencia adoptada y las razones subyacentes de cada elección:\n",
    "\n",
    "**Modelo Base - Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3FC+ReLU: </span>\n",
    "Iniciamos nuestra serie de pruebas con un modelo de perceptrón simple, compuesto por una única capa y un conjunto restringido de 1024 unidades ocultas. Esta configuración se eligió con el propósito de establecer un estándar inicial, lo que nos permitiría discernir el umbral de rendimiento básico asociado a nuestro conjunto de datos. El desempeño alcanzado por este modelo fue de un 49.61% de precisión en su mejor época.\n",
    "\n",
    "**Incremento de Capacidad en Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3FC_2+ReLU: </span>\n",
    "Preservando una estructura de capa ocult única, decidimos expandir la capacidad del modelo aumentando significativamente el número de neuronas. El total de unidades ocultas en este modelo revisado ascendió a 6144. Esta modificación fue realizada con el objetivo de investigar el impacto que una mayor capacidad, sin añadir profundidad adicional, podría tener sobre el desempeño del modelo. El rendimiento alcanzado por esta configuración fue de un 50.23% de precisión en su mejor época.\n",
    "\n",
    "**Introducción al Perceptrón Multicapa:** \n",
    "\n",
    "Se implementaron modelos con cuatro capas en total, basándonos en resultados anteriores:\n",
    "\n",
    "<span style=text-decoration:underline> 4FC+ReLU: </span>\n",
    "En el primer modelo multicapa, la estructura se derivó de la configuración óptima observada en los experimentos anteriores de perceptrón simple, añadiendo una capa adicional. El total de unidades ocultas en este nuevo modelo ascendió a 9216. Esta adición tenía como objetivo discernir el impacto de una mayor profundidad en la capacidad de extracción de características del modelo. El rendimiento alcanzado por esta configuración fue de un 52.88% de precisión en su mejor época.\n",
    "\n",
    "**Ampliación del Perceptrón Multicapa:** \n",
    "\n",
    "<span style=text-decoration:underline> 5FC+ReLU: </span>\n",
    "Frente a la mejora observada al incrementar la capacidad de una capa oculta adicional en el modelo previo, se procedió a implementar un modelo con cinco capas, tomando como base la arquitectura que previamente demostró ser más eficiente. La motivación detrás de esta ampliación radicaba en investigar si la adición progresiva de profundidad continuaría aportando mejoras significativas al rendimiento o si eventualmente se llegaría a un punto de rendimiento estancado o de saturación. Esta versión del modelo logró un desempeño de 54.99% de precisión en su mejor época.\n",
    "\n",
    "En términos de resultados, a pesar de las variaciones arquitectónicas implementadas, no se observaron discrepancias significativas en el rendimiento entre modelos. Aunque el modelo con cinco capas demostró ser marginalmente superior, la accuracy global promedio permaneció en torno al 50%. \n",
    "\n",
    "Una interpretación posible es que la utilización de capas lineales podría estar limitando la capacidad de los modelos para discernir y aprender relaciones más complejas presentes en el conjunto de datos. Es por ello que en las proximas secciones se exploraran las capas convolucionales.\n",
    "\n",
    "A continuación se presentan los resultados obtenidos para los modelos en wandb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/best_val_accuracy_2.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/train_time_2.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar se reportan el accuracy y el loss para train y validation del mejor y peor experimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_accuracy_2.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_accuracy_2.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_loss_2.png\" alt=\"Train Loss\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_loss_2.png\" alt=\"Validation Loss\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de los Gráficos:**\n",
    "\n",
    "1. **Train Accuracy:** El modelo con cinco capas densas (5FC+ReLU) parece tener una mejor precisión en el conjunto de entrenamiento en comparación con el modelo de tres capas (3FC+ReLU). Esto indica que la mayor profundidad puede estar capturando mejor las complejidades del conjunto de entrenamiento.\n",
    "\n",
    "2. **Val Accuracy:** La precisión en el conjunto de validación parece ser bastante similar para ambos modelos, aunque el modelo \"5FC+ReLU\" tiene una ligera ventaja. Esto sugiere que el incremento en la profundidad no está conduciendo a un sobreajuste significativo, ya que la precisión en la validación no disminuye.\n",
    "\n",
    "3. **Train Loss:** La pérdida en el entrenamiento es consistentemente más baja para el modelo \"5FC+ReLU\", lo cual es coherente con la mayor precisión de entrenamiento observada. Esto refleja que el modelo con mayor profundidad está aprendiendo más eficientemente.\n",
    "\n",
    "4. **Val Loss:** Aquí es donde se observa una discrepancia más notable. Mientras que la pérdida de validación para \"3FC+ReLU\" se mantiene relativamente estable y baja, la pérdida para \"5FC+ReLU\" aumenta significativamente en las últimas épocas. Este puede ser un indicador de sobreajuste, donde el modelo más profundo comienza a aprender ruido o patrones irrelevantes del conjunto de entrenamiento que no generalizan bien al conjunto de validación.\n",
    "\n",
    "**Conclusión:**\n",
    "El modelo \"5FC+ReLU\", con su arquitectura más profunda, tiene un mejor rendimiento en el conjunto de entrenamiento. Sin embargo, el incremento en la pérdida de validación en las últimas épocas puede ser una señal de alerta de que se está iniciando un sobreajuste. En un proximo inciso se explorará la utilización de técnicas como la regularización, early stopping, o ajustar el learning rate para tratar de minimizar este efecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Extienda el análisis utilizando capas convolucionales y reportar el mejor y peor experimento. ¿Cómo se compara? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos variando distintas funciones de activación y reportar el mejor y peor experimento. Explicar. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante esta fase del estudio, nos centramos en examinar cómo distintas funciones de activación afectan la eficacia de nuestra red neuronal convolucional (CNN), la cual, hasta el momento, ha demostrado ser la más prometedora en términos de desempeño. Las funciones de activación consideradas incluyen ReLU, LeakyReLU, SiLU y GELU.\n",
    "\n",
    "Desde el inicio de nuestro proyecto, hemos empleado la función ReLU como nuestro estándar, dada su eficiencia comprobada y su capacidad para mitigar el problema del gradiente desvaneciente en capas profundas. ReLU alcanzó un rendimiento del 74.29% en nuestras pruebas preliminares, lo que establece una sólida línea base para la comparación con otras funciones.\n",
    "\n",
    "Posteriormente, integramos LeakyReLU en nuestra arquitectura, motivados por su característica distintiva de permitir un pequeño gradiente cuando la unidad está inactiva, lo cual ayuda a mantener activas las neuronas que de otro modo podrían quedar permanentemente inactivas en ReLU. Este cambio resultó en una mejora marginal del rendimiento, elevándose a un 75.02%, lo que sugiere que la capacidad de LeakyReLU para evitar neuronas inactivas puede ser beneficioso para nuestro modelo.\n",
    "\n",
    "Nuestra experimentación continuó con la función de activación SiLU, también conocida como Swish, que es una función no monótona y suave que ha mostrado ventajas en ciertas arquitecturas de redes neuronales. Sin embargo, en nuestro contexto, SiLU obtuvo una precisión de 74.48%, la más baja entre las probadas. Esto podría atribuirse a la complejidad adicional que introduce SiLU, que no necesariamente se traduce en una ventaja en el conjunto de datos CIFAR-10, posiblemente debido a su naturaleza de imagen más sencilla en comparación con conjuntos de datos más complejos.\n",
    "\n",
    "Finalmente, exploramos el uso de GELU, inspirados por su desempeño en modelos de lenguaje natural de vanguardia, como BERT. GELU combina las propiedades de ReLU y distribuciones de probabilidad normalizadas, proporcionando una curva de activación más suave y continua. Este enfoque condujo a una ligera superioridad, con una precisión del 75.55%. Aunque la diferencia es modesta, GELU alcanzó el mayor rendimiento, lo cual podría atribuirse a su habilidad para producir una regulación más dinámica de las neuronas, posiblemente adaptándose mejor a la diversidad de patrones en el conjunto CIFAR-10.\n",
    "\n",
    "En resumen, aunque las diferencias de rendimiento entre las funciones de activación no son drásticas, la experimentación subraya la importancia de la selección de la función de activación en la arquitectura de una CNN. GELU se destaca ligeramente, lo que indica su potencial para mejorar el procesamiento de las señales neuronales en tareas de clasificación de imágenes.\n",
    "\n",
    "A continuación se presentan los resultados obtenidos para los modelos en wandb:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
