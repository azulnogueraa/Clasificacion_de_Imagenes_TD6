{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> <font style=\"bold\"> TD VI: Inteligencia Artificial </font></h1>\n",
    "    <h2><font style=\"bold\">Trabajo práctico 3: Clasificación de imágenes </font></h2>\n",
    "    <h3><font style=\"bold\">Integrantes:</font></h3>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <h4><ul>\n",
    "        <li>Noguera Azul</li>\n",
    "        <li>Gonzalez Rocio</li>\n",
    "        <li>Guledjian Patricio</li>\n",
    "        </ul>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "<span style=color:lightblue> Crearse una cuenta en Weights and Biases y linkear la notebook a este. Cada experimento deberá contener nombres dicientes y almacenar los (hiper)parámetros de configuración del mismo. Deberá separar los sets de datos en entrenamiento, validación y test. Utilizando solamente los sets de entrenamiento y validación, registrar la loss en train y validación en cada iteración que considere conveniente. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este trabajo práctico es evaluar los distintos hiperparámetros encontrados durante el\n",
    "entrenamiento de una red neuronal, evaluarlos y elegir el conjunto de parámetros más óptimos.\n",
    "En el marco de este trabajo práctico, se realizará un clasificador de imágenes CIFAR-10.\n",
    "\n",
    "CIFAR-10 es un conjunto de datos que contiene 60,000 imágenes de 10 clases de pájaros, gatos, venados, perros, ranas, caballos, barcos y camiones; y se considera un conjunto de datos típico para problemas de visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos variando cantidad de capas densas, nodos, hidden layers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el proceso de experimentación con perceptrones, adoptamos un enfoque sistemático y justificado para evaluar diferentes arquitecturas y configuraciones. A continuación, se detalla la secuencia adoptada y las razones subyacentes de cada elección:\n",
    "\n",
    "**Modelo Base - Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3fcLayers_fewNodes: </span>\n",
    "La experimentación se inició con un modelo de perceptrón simple con una capa y un número limitado de neuronas. Esta elección se fundamentó en la necesidad de establecer un punto de referencia básico, permitiéndonos determinar el rendimiento mínimo requerido para el conjunto de datos en cuestión.\n",
    "\n",
    "**Incremento de Capacidad en Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3fcLayers_++Nodes: </span>\n",
    "Reteniendo una única capa, el modelo se amplió con un incremento significativo en el número de neuronas. Esta configuración tenía el propósito de analizar cómo una mayor capacidad, sin agregar profundidad, influiría en el rendimiento.\n",
    "\n",
    "**Introducción al Perceptrón Multicapa:** \n",
    "\n",
    "Se implementaron modelos con cuatro capas en total, basándonos en resultados anteriores:\n",
    "\n",
    "<span style=text-decoration:underline> 4fcLayers_equalNodes: </span>\n",
    "En el primer modelo multicapa, la estructura se derivó de la configuración óptima observada en los experimentos anteriores de perceptrón simple, añadiendo una capa adicional. Esta adición tenía como objetivo discernir el impacto de una mayor profundidad en la capacidad de extracción de características del modelo.\n",
    "\n",
    "<span style=text-decoration:underline> 4fcLayers_gradualNodesreduction: </span>\n",
    "En una variación posterior, manteniendo una estructura similar, se ajustó la distribución de neuronas para conseguir una reducción gradual a través de las capas. La lógica detrás de esta elección radicaba en la posibilidad de que al condensar la información, la red podría priorizar características más significativas y mejorar la eficiencia general.\n",
    "\n",
    "\n",
    "**Ampliación del Perceptrón Multicapa:** \n",
    "\n",
    "<span style=text-decoration:underline> 5fcLayers_gradualNodesreduction: </span>\n",
    "Se introdujo un modelo con cinco capas, fundamentándose en la arquitectura que previamente demostró ser más eficaz. El propósito de esta expansión era evaluar si la adición continua de profundidad ofrecería mejoras sustanciales en el rendimiento o si se alcanzaría un punto de saturación.\n",
    "\n",
    "En términos de resultados, a pesar de las variaciones arquitectónicas implementadas, no se observaron discrepancias significativas en el rendimiento entre modelos. Aunque el modelo con reducción gradual de neuronas con 4 capas (4fcLayers_gradualNodesreduction) demostró ser marginalmente superior, la accuracy global promedio permaneció en torno al 50%. \n",
    "\n",
    "Una interpretación posible es que la utilización de capas lineales podría estar limitando la capacidad de los modelos para discernir y aprender relaciones más complejas presentes en el conjunto de datos. Es por ello que en las proximas secciones se exploraran las capas convolucionales."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
