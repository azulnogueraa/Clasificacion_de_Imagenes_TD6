{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> <font style=\"bold\"> TD VI: Inteligencia Artificial </font></h1>\n",
    "    <h2><font style=\"bold\">Trabajo práctico 3: Clasificación de imágenes </font></h2>\n",
    "    <h3><font style=\"bold\">Integrantes:</font></h3>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <h4><ul>\n",
    "        <li>Noguera Azul</li>\n",
    "        <li>Gonzalez Rocio</li>\n",
    "        <li>Guledjian Patricio</li>\n",
    "        </ul>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=color:lightblue> Crearse una cuenta en Weights and Biases y linkear la notebook a este. Cada experimento deberá contener nombres dicientes y almacenar los (hiper)parámetros de configuración del mismo. Deberá separar los sets de datos en entrenamiento, validación y test. Utilizando solamente los sets de entrenamiento y validación, registrar la loss en train y validación en cada iteración que considere conveniente. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este trabajo práctico es evaluar los distintos hiperparámetros encontrados durante el\n",
    "entrenamiento de una red neuronal, evaluarlos y elegir el conjunto de parámetros más óptimos.\n",
    "En el marco de este trabajo práctico, se realizará un clasificador de imágenes CIFAR-10.\n",
    "\n",
    "CIFAR-10 es un conjunto de datos que contiene 60,000 imágenes de 10 clases de pájaros, gatos, venados, perros, ranas, caballos, barcos y camiones; y se considera un conjunto de datos típico para problemas de visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos variando cantidad de capas densas, nodos, hidden layers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el proceso de experimentación con perceptrones, adoptamos un enfoque sistemático y justificado para evaluar diferentes arquitecturas y configuraciones. A continuación, se detalla la secuencia adoptada y las razones subyacentes de cada elección:\n",
    "\n",
    "**Modelo Base - Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3FC+ReLU: </span>\n",
    "Iniciamos nuestra serie de pruebas con un modelo de perceptrón simple, compuesto por una única capa y un conjunto restringido de 1024 unidades ocultas. Esta configuración se eligió con el propósito de establecer un estándar inicial, lo que nos permitiría discernir el umbral de rendimiento básico asociado a nuestro conjunto de datos. El desempeño alcanzado por este modelo fue de un 49.61% de precisión en su mejor época.\n",
    "\n",
    "**Incremento de Capacidad en Perceptrón Simple:**\n",
    "\n",
    "<span style=text-decoration:underline> 3FC_2+ReLU: </span>\n",
    "Preservando una estructura de capa ocult única, decidimos expandir la capacidad del modelo aumentando significativamente el número de neuronas. El total de unidades ocultas en este modelo revisado ascendió a 6144. Esta modificación fue realizada con el objetivo de investigar el impacto que una mayor capacidad, sin añadir profundidad adicional, podría tener sobre el desempeño del modelo. El rendimiento alcanzado por esta configuración fue de un 50.23% de precisión en su mejor época.\n",
    "\n",
    "**Introducción al Perceptrón Multicapa:** \n",
    "\n",
    "Se implementaron modelos con cuatro capas en total, basándonos en resultados anteriores:\n",
    "\n",
    "<span style=text-decoration:underline> 4FC+ReLU: </span>\n",
    "En el primer modelo multicapa, la estructura se derivó de la configuración óptima observada en los experimentos anteriores de perceptrón simple, añadiendo una capa adicional. El total de unidades ocultas en este nuevo modelo ascendió a 9216. Esta adición tenía como objetivo discernir el impacto de una mayor profundidad en la capacidad de extracción de características del modelo. El rendimiento alcanzado por esta configuración fue de un 52.88% de precisión en su mejor época.\n",
    "\n",
    "**Ampliación del Perceptrón Multicapa:** \n",
    "\n",
    "<span style=text-decoration:underline> 5FC+ReLU: </span>\n",
    "Frente a la mejora observada al incrementar la capacidad de una capa oculta adicional en el modelo previo, se procedió a implementar un modelo con cinco capas, tomando como base la arquitectura que previamente demostró ser más eficiente. La motivación detrás de esta ampliación radicaba en investigar si la adición progresiva de profundidad continuaría aportando mejoras significativas al rendimiento o si eventualmente se llegaría a un punto de rendimiento estancado o de saturación. Esta versión del modelo logró un desempeño de 54.99% de precisión en su mejor época.\n",
    "\n",
    "En términos de resultados, a pesar de las variaciones arquitectónicas implementadas, no se observaron discrepancias significativas en el rendimiento entre modelos. Aunque el modelo con cinco capas demostró ser marginalmente superior, la accuracy global promedio permaneció en torno al 50%. \n",
    "\n",
    "Una interpretación posible es que la utilización de capas lineales podría estar limitando la capacidad de los modelos para discernir y aprender relaciones más complejas presentes en el conjunto de datos. Es por ello que en las proximas secciones se exploraran las capas convolucionales.\n",
    "\n",
    "A continuación se presentan los resultados obtenidos para los modelos en wandb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/best_val_accuracy_2.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/train_time_2.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar se reportan el accuracy y el loss para train y validation del mejor y peor experimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_accuracy_2.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_accuracy_2.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_loss_2.png\" alt=\"Train Loss\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_loss_2.png\" alt=\"Validation Loss\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de los Gráficos:**\n",
    "\n",
    "1. **Train Accuracy:** El modelo con cinco capas densas (5FC+ReLU) parece tener una mejor precisión en el conjunto de entrenamiento en comparación con el modelo de tres capas (3FC+ReLU). Esto indica que la mayor profundidad puede estar capturando mejor las complejidades del conjunto de entrenamiento.\n",
    "\n",
    "2. **Val Accuracy:** La precisión en el conjunto de validación parece ser bastante similar para ambos modelos, aunque el modelo \"5FC+ReLU\" tiene una ligera ventaja. Esto sugiere que el incremento en la profundidad no está conduciendo a un sobreajuste significativo, ya que la precisión en la validación no disminuye.\n",
    "\n",
    "3. **Train Loss:** La pérdida en el entrenamiento es consistentemente más baja para el modelo \"5FC+ReLU\", lo cual es coherente con la mayor precisión de entrenamiento observada. Esto refleja que el modelo con mayor profundidad está aprendiendo más eficientemente.\n",
    "\n",
    "4. **Val Loss:** Aquí es donde se observa una discrepancia más notable. Mientras que la pérdida de validación para \"3FC+ReLU\" se mantiene relativamente estable y baja, la pérdida para \"5FC+ReLU\" aumenta significativamente en las últimas épocas. Este puede ser un indicador de sobreajuste, donde el modelo más profundo comienza a aprender ruido o patrones irrelevantes del conjunto de entrenamiento que no generalizan bien al conjunto de validación.\n",
    "\n",
    "**Conclusión:**\n",
    "El modelo \"5FC+ReLU\", con su arquitectura más profunda, tiene un mejor rendimiento en el conjunto de entrenamiento. Sin embargo, el incremento en la pérdida de validación en las últimas épocas puede ser una señal de alerta de que se está iniciando un sobreajuste. En un proximo inciso se explorará la utilización de técnicas como la regularización, early stopping, o ajustar el learning rate para tratar de minimizar este efecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Extienda el análisis utilizando capas convolucionales y reportar el mejor y peor experimento. ¿Cómo se compara? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la fase actual de la experimentación, replicamos la metodología del paso anterior, donde partimos de una red neuronal convolucional (CNN) básica y progresivamente incrementamos la complejidad mediante la adición de capas y la variación en el número de canales de salida, observando sus efectos en el rendimiento. Cabe señalar que durante este proceso, mantuvimos constantes el resto de los hiperparámetros, para aislar el impacto de los cambios estructurales en la red.\n",
    "\n",
    "**2Conv+2FC+ReLU:** \n",
    "La configuración inicial constaba de dos capas convolucionales seguidas de dos capas completamente conectadas (fully connected - FC), empleando la función de activación ReLU y MaxPooling de 2x2 después de cada capa convolucional. Optamos por un kernel de tamaño reducido y un stride de 2 para incrementar la localidad de las características aprendidas y reducir las dimensiones espaciales de la representación, lo que se esperaría que condujese a una mayor eficiencia en términos computacionales. La precisión máxima alcanzada por este modelo fue del 67.18%.\n",
    "\n",
    "**3Conv+2FC+ReLU:** \n",
    "Con base en el incremento de rendimiento observado al pasar de redes densas a convolucionales, añadimos una tercera capa convolucional para capturar características más abstractas y complejas, lo que podría potenciar la capacidad de generalización del modelo. Esta modificación resultó en una mejora de rendimiento, alcanzando una precisión del 70.12%.\n",
    "\n",
    "**4Conv+2FC+ReLU:** \n",
    "Anticipando que la adición de capas pudiera seguir beneficiando al modelo por la mayor profundidad y capacidad de extracción de características, incorporamos una cuarta capa convolucional. Contrario a lo esperado, la precisión disminuyó ligeramente a 69.75%. Este descenso podría explicarse por un sobreajuste debido a la mayor complejidad del modelo o por dificultades en la optimización durante el entrenamiento debido a la profundización de la red.\n",
    "\n",
    "Tras evaluar los resultados, decidimos reevaluar la arquitectura con tres capas convolucionales, focalizándonos en la variación del número de canales de salida.\n",
    "\n",
    "**3Conv+2FC_2+ReLU:** \n",
    "En el experimento final, incrementamos sustancialmente el número de canales de salida en cada una de las capas convolucionales, ajustando a 256, 512 y 128 respectivamente. Esta expansión en la capacidad representacional del modelo se reflejó en un significativo aumento de la precisión, alcanzando el 74.29% en su mejor época, lo cual convierte a esta arquitectura en la más efectiva entre las probadas en esta serie de experimentos. Este éxito puede atribuirse a la combinación de una profundidad adecuada con una capacidad aumentada para representar y procesar la información de entrada a lo largo de la red.\n",
    "\n",
    "A continuación se presentan los resultados obtenidos para los modelos en wandb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/best_val_accuracy_3.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/train_time_3.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fundamental subrayar que mientras la arquitectura con el rendimiento más elevado garantiza una mejora en la precisión, incurre también en un costo incrementado en términos de tiempo de computación, específicamente 247 segundos para el entrenamiento. Esta arquitectura es la más exigente temporalmente debido a su mayor profundidad.\n",
    "\n",
    "Para finalizar se reportan el accuracy y el loss para train y validation del mejor y peor experimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_accuracy_3.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_accuracy_3.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_loss_3.png\" alt=\"Train Loss\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_loss_3.png\" alt=\"Validation Loss\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Train Accuracy:** \n",
    "El primer gráfico, muestra que la arquitectura \"3Conv+2FC_2+ReLU\" y \"2Conv+2FC+ReLU\" tienen trayectorias de precisión de entrenamiento similares, ambas incrementando de manera constante a medida que avanzan las épocas. La convergencia de ambas líneas sugiere que, en términos de ajuste al conjunto de entrenamiento, ambas arquitecturas aprenden con eficacia y alcanzan niveles similares de precisión.\n",
    "\n",
    "1. **Val Accuracy:**\n",
    "En el gráfico que mide la precisión de validación, vemos que la arquitectura con tres capas convolucionales supera ligeramente a la de dos capas a lo largo de las épocas. Esto indica que, aunque ambas redes generalizan de forma similar, la arquitectura más profunda tiene una ligera ventaja en la generalización en datos no vistos.\n",
    "\n",
    "1. **Train y Val Loss:**\n",
    "Pasando a los gráficos de pérdida (\"train_loss\" y \"val_loss\"), observamos que la pérdida de entrenamiento disminuye para ambas arquitecturas a medida que aumenta el número de épocas, lo cual es esperado, ya que el modelo se está optimizando y ajustando a los datos de entrenamiento. Sin embargo, en \"val_loss\", vemos que la arquitectura \"3Conv+2FC_2+ReLU\" comienza a experimentar un aumento en la pérdida de validación después de aproximadamente seis épocas, lo cual podría ser un indicador de sobreajuste, donde el modelo se ajusta demasiado a los datos de entrenamiento y pierde la capacidad de generalizar bien.\n",
    "\n",
    "\n",
    "La pérdida de validación es un factor crucial en el diseño de modelos de aprendizaje profundo, ya que proporciona una evaluación más robusta de cómo el modelo se desempeñará con datos no vistos, en comparación con la pérdida de entrenamiento, que simplemente refleja el ajuste del modelo a los datos de entrenamiento. Por lo tanto, aunque \"3Conv+2FC_2+ReLU\" tiene una mayor precisión de validación, el incremento de la pérdida de validación indica que puede ser susceptible a sobreajuste y podría beneficiarse de técnicas de regularización como dropout y batch normalization que experimentaremos en los proximos incisos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparación CNN vs FC**\n",
    "\n",
    "Al evaluar las arquitecturas que utilizan capas convolucionales frente a las que se basan exclusivamente en capas densas, se observa una superioridad de rendimiento en las Redes Neuronales Convolucionales (CNNs). La ventaja distintiva de las CNNs radica en su habilidad para capturar representaciones más efectivas y resistentes de datos visuales. Esto es resultado de su estructura única, que conserva las correlaciones espaciales entre píxeles y, simultáneamente, disminuye el número de parámetros requeridos mediante el mecanismo de compartición de pesos. Tal eficiencia no solo mejora la capacidad de generalización del modelo, sino que también optimiza el uso computacional.\n",
    "\n",
    "Por otro lado, desde la perspectiva del rendimiento computacional, es cierto que las CNNs exigen un mayor esfuerzo de recursos en el entrenamiento debido a las operaciones de convolución involucradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos variando distintas funciones de activación y reportar el mejor y peor experimento. Explicar. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante esta fase del estudio, nos centramos en examinar cómo distintas funciones de activación afectan la eficacia de nuestra red neuronal convolucional (CNN), la cual, hasta el momento, ha demostrado ser la más prometedora en términos de desempeño. Las funciones de activación consideradas incluyen ReLU, LeakyReLU, SiLU y GELU.\n",
    "\n",
    "Desde el inicio de nuestro proyecto, hemos empleado la función ReLU como nuestro estándar, dada su eficiencia comprobada y su capacidad para mitigar el problema del gradiente desvaneciente en capas profundas. ReLU alcanzó un rendimiento del 74.29% en nuestras pruebas preliminares, lo que establece una sólida línea base para la comparación con otras funciones.\n",
    "\n",
    "Posteriormente, integramos LeakyReLU en nuestra arquitectura, motivados por su característica distintiva de permitir un pequeño gradiente cuando la unidad está inactiva, lo cual ayuda a mantener activas las neuronas que de otro modo podrían quedar permanentemente inactivas en ReLU. Este cambio resultó en una mejora marginal del rendimiento, elevándose a un 75.02%, lo que sugiere que la capacidad de LeakyReLU para evitar neuronas inactivas puede ser beneficioso para nuestro modelo.\n",
    "\n",
    "Nuestra experimentación continuó con la función de activación SiLU, también conocida como Swish, que es una función no monótona y suave que ha mostrado ventajas en ciertas arquitecturas de redes neuronales. Sin embargo, en nuestro contexto, SiLU obtuvo una precisión de 74.48%, la más baja entre las probadas. Esto podría atribuirse a la complejidad adicional que introduce SiLU, que no necesariamente se traduce en una ventaja en el conjunto de datos CIFAR-10, posiblemente debido a su naturaleza de imagen más sencilla en comparación con conjuntos de datos más complejos.\n",
    "\n",
    "Finalmente, exploramos el uso de GELU, inspirados por su desempeño en modelos de lenguaje natural de vanguardia, como BERT. GELU combina las propiedades de ReLU y distribuciones de probabilidad normalizadas, proporcionando una curva de activación más suave y continua. Este enfoque condujo a una ligera superioridad, con una precisión del 75.55%. Aunque la diferencia es modesta, GELU alcanzó el mayor rendimiento, lo cual podría atribuirse a su habilidad para producir una regulación más dinámica de las neuronas, posiblemente adaptándose mejor a la diversidad de patrones en el conjunto CIFAR-10.\n",
    "\n",
    "En resumen, aunque las diferencias de rendimiento entre las funciones de activación no son drásticas, la experimentación subraya la importancia de la selección de la función de activación en la arquitectura de una CNN. GELU se destaca ligeramente, lo que indica su potencial para mejorar el procesamiento de las señales neuronales en tareas de clasificación de imágenes.\n",
    "\n",
    "A continuación se presentan los resultados obtenidos para los modelos en wandb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/best_val_accuracy_4.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/train_time_4.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar se reportan el accuracy y el loss para train y validation del mejor y peor experimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_accuracy_4.png\" alt=\"Train Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_accuracy_4.png\" alt=\"Validation Accuracy\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"imagenes/train_loss_4.png\" alt=\"Train Loss\" style=\"width: 400px;\"/> </td>\n",
    "            <td> <img src=\"imagenes/val_loss_4.png\" alt=\"Validation Loss\" style=\"width: 400px;\"/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Accuracy:** Ambas redes muestran un incremento constante en la precisión a medida que avanzan las épocas. La red con ReLU muestra una precisión marginalmente mayor en comparación con la red que utiliza GELU, aunque la diferencia es pequeña, lo que indica que ambas funciones de activación están logrando un aprendizaje similar en el conjunto de entrenamiento.\n",
    "\n",
    "**Val Accuracy:** La precisión en el conjunto de validación se estabiliza para ambas redes después de las primeras épocas. La red con GELU muestra una ligera ventaja inicial, pero hacia el final del entrenamiento, las dos redes convergen a una precisión similar. La estabilización temprana de la precisión en validación sugiere que ambas redes han alcanzado su capacidad de generalización óptima dadas las arquitecturas y los datos proporcionados.\n",
    "\n",
    "**Train Loss:** Se observa una disminución constante de la pérdida para ambas redes, lo cual es esperado ya que la red se está optimizando para minimizar la función de pérdida. La red con ReLU muestra una disminución ligeramente más pronunciada, lo que implica que está ajustando mejor los parámetros en el conjunto de entrenamiento en comparación con la red GELU.\n",
    "\n",
    "**Val Loss:** En cuanto a la pérdida de validación, ambas arquitecturas presentan una disminución inicial, seguida de un aumento. Este comportamiento es indicativo de sobreajuste, donde la red comienza a memorizar los datos de entrenamiento en lugar de aprender a generalizar. Sin embargo, es notable que la red con GELU parece tener una menor pérdida de validación en las últimas épocas en comparación con la red con ReLU, lo que puede indicar una mejor capacidad de generalización bajo la función de activación GELU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:lightblue> Realizar experimentos evaluando distintos optimizadores, schedulers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron? <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la fase experimental, nuestra meta fue optimizar el rendimiento de una red neuronal profundizando en la selección de distintos optimizadores y programadores de la tasa de aprendizaje. Partimos del modelo de referencia que, en ensayos previos, había demostrado ser altamente eficaz: una red convolucional dotada de la función de activación GELU.\n",
    "\n",
    "Iniciamos el proceso con el optimizador SGD y una tasa de aprendizaje de 0.02, elegido por su reconocida eficacia en el manejo de gradientes y su capacidad para converger de manera estable en amplias variedades de problemas. El resultado fue prometedor, alcanzando un 75.55% de precisión en la validación. A pesar de este resultado favorable, nos propusimos ampliar el espectro de pruebas para verificar la existencia de márgenes de mejora.\n",
    "\n",
    "Seguidamente, probamos con Adagrad manteniendo el learning rate en 0.02, atraídos por su adaptabilidad en la actualización de tasas de aprendizaje por parámetro, lo cual es particularmente útil en escenarios con distribuciones de datos esporádicos. Contrariamente a nuestras expectativas, observamos una caída significativa en la precisión, descendiendo al 68.17%. Tal reducción podría atribuirse a una falta de sinergia entre las características adaptativas de Adagrad y la dinámica de nuestro modelo, o quizá a la necesidad de una calibración más fina del learning rate.\n",
    "\n",
    "El optimizador Adam fue el siguiente candidato, manteniendo inicialmente el learning rate de 0.02. Seleccionamos Adam debido a su combinación de las ventajas de dos extensiones de gradiente descendente: RMSprop y SGD con momentum. A pesar de su popularidad y eficacia general, el rendimiento fue subóptimo, lo que nos condujo a la hipótesis de que Adam suele ser más eficiente con tasas de aprendizaje reducidas, ya que ajusta de manera más precisa las actualizaciones de los pesos aprovechando estimaciones del primer y segundo momento del gradiente.\n",
    "\n",
    "Con esta teoría en mente, ajustamos el learning rate a 0.001 para aprovechar la sensibilidad de Adam a variaciones más pequeñas durante el aprendizaje. Este ajuste dio lugar a una mejora notable, elevando la precisión al 75.17%. A pesar de que este resultado mejoró el obtenido con Adagrad, aún no logró superar el rendimiento del SGD inicial.\n",
    "\n",
    "En un intento final, apostamos por reducir aún más el learning rate con Adam, esta vez a 0.0001. La precisión resultante fue de 75.54%, casi idéntica a la alcanzada con el SGD, lo que subraya la capacidad de Adam de alcanzar una convergencia eficiente utilizando tasas de aprendizaje extremadamente bajas, facilitando así un ajuste más detallado sin sacrificar la velocidad de convergencia.\n",
    "\n",
    "Esta serie de experimentos subraya la importancia crítica de seleccionar y afinar el optimizador y la tasa de aprendizaje adecuados en función de las características específicas del modelo y la naturaleza del problema de aprendizaje profundo que se aborda."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
